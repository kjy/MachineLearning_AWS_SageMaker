{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Data Cleansing and Feature Engineering\n",
    "\n",
    "In this exercise, we'll be loading in a dataset that has some problems. In order for us to get it ready for our models, we will apply some of the technics we learned.\n",
    "\n",
    "Apply these changes to the `data.csv` dataset.\n",
    "1. Load `data.csv` into a dataframe.\n",
    "2. Output the table info to see if there are any null values.\n",
    "3. Remove all null values from the dataframe.\n",
    "4. Change the `date` column from an object to a `datetime64[ns]` type.\n",
    "5. Change the `weather` column to a category type.\n",
    "6. One hot encode the `date` column to year, month, and day.\n",
    "7. Normalized the columns from the `all_features` list so each feature has a zero mean.\n",
    "8. Create and save the cleaned dataframe, as well as the train/validation/test dataframes to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset created by 02_exercise_dataset_creation.ipynb\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always good to check to see if the data looks right\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output general info about the table, notice we have some null values in all of our features\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the date column to a datetime\n",
    "df.loc[:, 'date'] = pd.to_datetime(df.loc[:,\"date\"])\n",
    "# Change weather column to a category\n",
    "df.loc[:, 'weather'] = df[\"weather\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year, month, and day into separate columns\n",
    "df['year'] = df.date.dt.year\n",
    "df['month'] = df.date.dt.month\n",
    "df['day'] = df.date.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the weather category to have individual features. Prefix with `weather`\n",
    "weather_one_hot_df = pd.get_dummies(df.weather, prefix=\"weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the one hot encoded values back to the df\n",
    "df[weather_one_hot_df.columns.to_list()] = weather_one_hot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify now that are table info has no nulls and correct Dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These may change if you decided to call your columns different from above\n",
    "all_features = [\n",
    "    \"feature0\",\n",
    "    \"feature1\",\n",
    "    \"feature2\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"weather_cloudy\",\n",
    "    \"weather_rainy\",\n",
    "    \"weather_sunny\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table summary, notice the mean to many of our tables are not zero.\n",
    "df[all_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize feature values to have a zero mean\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[all_features])\n",
    "df.loc[:, all_features] = scaler.transform(df[all_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify our features we are using now all have zero mean\n",
    "df[all_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "# train: 0.6 | validation: 0.2\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.25, random_state=0)\n",
    "\n",
    "# Final dataset sizes: train: 0.6, validation: 0.2, text: 0.2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output each shape to confirm the size of train/validation/test\n",
    "print(f\"Train: {df_train.shape}\")\n",
    "print(f\"Validation: {df_val.shape}\")\n",
    "print(f\"Test: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all clean data, and the train, validation, test data as csv\n",
    "df.to_csv(\"data_clean.csv\", index=False)\n",
    "df_train.to_csv(\"train.csv\", index=False)\n",
    "df_val.to_csv(\"validation.csv\", index=False)\n",
    "df_test.to_csv(\"test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
