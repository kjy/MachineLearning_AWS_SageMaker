{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Model Training and Evaluation\n",
    "\n",
    "Now that we have the data fundamentals for creating, cleaning, and modifying our datasets, we can train and evaluate a model, in this case it's a linear regression model.\n",
    "\n",
    "Your tasks for this exercise are:\n",
    "1. Create a dataframe with the regression dataset, include the features and target within the same dataframe.\n",
    "2. Create a 60% Train / 20% Validation / 20% Test dataset group using the `train_test_split` method.\n",
    "3. Fit the LinearRegression model on the training set.\n",
    "4. Evaluate the model on the validation set.\n",
    "5. Evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_dataset = make_regression(\n",
    "    n_samples=10000,\n",
    "    n_features=10,\n",
    "    n_informative=5,\n",
    "    bias=0,\n",
    "    noise=40,\n",
    "    n_targets=1,\n",
    "    random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe using the dataset\n",
    "df = pd.DataFrame(regression_dataset[0])\n",
    "df[\"target\"] = regression_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `.head()` to view what the dataset looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "# train: 0.6 | validation: 0.2\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.25, random_state=0)\n",
    "\n",
    "# Final dataset sizes: train: 0.6, validation: 0.2, text: 0.2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output each shape to confirm the size of train/validation/test\n",
    "print(f\"Train: {df_train.shape}\")\n",
    "print(f\"Validation: {df_val.shape}\")\n",
    "print(f\"Test: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the linear model by fitting it on the dataframe features and dataframe target\n",
    "reg = LinearRegression().fit(df_train[range(10)], df_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the linear model by scoring it, by default it's the metric r2.\n",
    "reg.score(df_val[range(10)], df_val[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once done optimizing the model using the validation dataset,\n",
    "# Evaluate the linear model by scoring it on the test dataset.\n",
    "reg.score(df_test[range(10)], df_test[\"target\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
